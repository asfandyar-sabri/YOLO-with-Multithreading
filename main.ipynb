{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TDjnpiglAhhf",
    "outputId": "df0a1810-cf80-4c42-b1b1-aaadcf281193"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'YOLOX'...\n",
      "remote: Enumerating objects: 1723, done.\u001b[K\n",
      "remote: Counting objects: 100% (1/1), done.\u001b[K\n",
      "remote: Total 1723 (delta 0), reused 1 (delta 0), pack-reused 1722\u001b[K\n",
      "Receiving objects: 100% (1723/1723), 6.83 MiB | 22.14 MiB/s, done.\n",
      "Resolving deltas: 100% (1020/1020), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/Megvii-BaseDetection/YOLOX.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D_NaN_8PAjro",
    "outputId": "882e6458-a009-480b-bb68-c247c54bec2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-08-31 12:28:02--  https://github.com/Megvii-BaseDetection/YOLOX/releases/download/0.1.1rc0/yolox_m.pth\n",
      "Resolving github.com (github.com)... 20.205.243.166\n",
      "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/386811486/a0b0f1ca-0e3c-43e4-829d-d9177f6be5f7?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220831%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220831T122802Z&X-Amz-Expires=300&X-Amz-Signature=99f11799fa3d506613e4831186fc2bcdedc9e850a1d2425670ab6c863ef31a25&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=386811486&response-content-disposition=attachment%3B%20filename%3Dyolox_m.pth&response-content-type=application%2Foctet-stream [following]\n",
      "--2022-08-31 12:28:02--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/386811486/a0b0f1ca-0e3c-43e4-829d-d9177f6be5f7?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220831%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220831T122802Z&X-Amz-Expires=300&X-Amz-Signature=99f11799fa3d506613e4831186fc2bcdedc9e850a1d2425670ab6c863ef31a25&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=386811486&response-content-disposition=attachment%3B%20filename%3Dyolox_m.pth&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 203114461 (194M) [application/octet-stream]\n",
      "Saving to: ‘yolox_m.pth’\n",
      "\n",
      "yolox_m.pth         100%[===================>] 193.70M  5.91MB/s    in 26s     \n",
      "\n",
      "2022-08-31 12:28:29 (7.34 MB/s) - ‘yolox_m.pth’ saved [203114461/203114461]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/Megvii-BaseDetection/YOLOX/releases/download/0.1.1rc0/yolox_m.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uprKUirnAnRW",
    "outputId": "5a61add8-c35b-4b1e-9a92-a9d5e909c867"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Processing ./YOLOX\n",
      "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
      "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from yolox==0.3.0) (1.21.6)\n",
      "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.7/dist-packages (from yolox==0.3.0) (1.12.1+cu113)\n",
      "Requirement already satisfied: opencv_python in /usr/local/lib/python3.7/dist-packages (from yolox==0.3.0) (4.6.0.66)\n",
      "Collecting loguru\n",
      "  Downloading loguru-0.6.0-py3-none-any.whl (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 6.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from yolox==0.3.0) (4.64.0)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from yolox==0.3.0) (0.13.1+cu113)\n",
      "Collecting thop\n",
      "  Downloading thop-0.1.1.post2207130030-py3-none-any.whl (15 kB)\n",
      "Collecting ninja\n",
      "  Downloading ninja-1.10.2.3-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (108 kB)\n",
      "\u001b[K     |████████████████████████████████| 108 kB 65.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from yolox==0.3.0) (0.8.10)\n",
      "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from yolox==0.3.0) (2.0.4)\n",
      "Collecting onnx==1.8.1\n",
      "  Downloading onnx-1.8.1-cp37-cp37m-manylinux2010_x86_64.whl (14.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.5 MB 17.3 MB/s \n",
      "\u001b[?25hCollecting onnxruntime==1.8.0\n",
      "  Downloading onnxruntime-1.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.5 MB 49.5 MB/s \n",
      "\u001b[?25hCollecting onnx-simplifier==0.3.5\n",
      "  Downloading onnx-simplifier-0.3.5.tar.gz (13 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx==1.8.1->yolox==0.3.0) (4.1.1)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnx==1.8.1->yolox==0.3.0) (3.17.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from onnx==1.8.1->yolox==0.3.0) (1.15.0)\n",
      "Collecting onnxoptimizer>=0.2.5\n",
      "  Downloading onnxoptimizer-0.3.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (602 kB)\n",
      "\u001b[K     |████████████████████████████████| 602 kB 42.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime==1.8.0->yolox==0.3.0) (2.0.7)\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools>=2.0.2->yolox==0.3.0) (3.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->yolox==0.3.0) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->yolox==0.3.0) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->yolox==0.3.0) (1.4.4)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->yolox==0.3.0) (3.0.9)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->yolox==0.3.0) (7.1.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->yolox==0.3.0) (2.23.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->yolox==0.3.0) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->yolox==0.3.0) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->yolox==0.3.0) (2022.6.15)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->yolox==0.3.0) (3.0.4)\n",
      "Building wheels for collected packages: yolox, onnx-simplifier\n",
      "  Building wheel for yolox (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for yolox: filename=yolox-0.3.0-cp37-cp37m-linux_x86_64.whl size=1053204 sha256=8d6836ae250ac403374908ededea8762816ab95b3eca9378f3b8ef1741637f71\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ih3p26w2/wheels/b6/9c/fc/282adc5181cca746b2c612471766219d67e7619ae02feb2c65\n",
      "  Building wheel for onnx-simplifier (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for onnx-simplifier: filename=onnx_simplifier-0.3.5-py3-none-any.whl size=12878 sha256=f108c22786639e11049a4fd87ba9d85914afdde6c43693b4f1e8267a68408123\n",
      "  Stored in directory: /root/.cache/pip/wheels/8a/b4/1b/6acdd4eb854b215cd4aa1c18ca79399f9d34728edaff47ecce\n",
      "Successfully built yolox onnx-simplifier\n",
      "Installing collected packages: onnx, onnxruntime, onnxoptimizer, thop, onnx-simplifier, ninja, loguru, yolox\n",
      "Successfully installed loguru-0.6.0 ninja-1.10.2.3 onnx-1.8.1 onnx-simplifier-0.3.5 onnxoptimizer-0.3.1 onnxruntime-1.8.0 thop-0.1.1.post2207130030 yolox-0.3.0\n"
     ]
    }
   ],
   "source": [
    "pip install YOLOX/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NRHmDdH6TdDo"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "from unittest import result\n",
    "from loguru import logger\n",
    "import cv2\n",
    "from google.colab.patches import cv2_imshow as im\n",
    "from threading import Thread\n",
    "\n",
    "import torch\n",
    "\n",
    "from yolox.data.data_augment import ValTransform\n",
    "from yolox.data.datasets import COCO_CLASSES\n",
    "from yolox.exp import get_exp\n",
    "from yolox.utils import fuse_model, get_model_info, postprocess, vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "baS98VUk_c3p"
   },
   "outputs": [],
   "source": [
    "IMAGE_EXT = [\".jpg\", \".jpeg\", \".webp\", \".bmp\", \".png\"]\n",
    "\n",
    "class Yolox(object):\n",
    "    def __init__(\n",
    "        self,\n",
    "        exp_name,\n",
    "        ckpt,\n",
    "        conf=0.25,\n",
    "        nms=0.45,\n",
    "        img_size=None,\n",
    "        cls_names=COCO_CLASSES,\n",
    "        decoder=None,\n",
    "        device=\"cpu\",\n",
    "        fp16=False,\n",
    "        legacy=False,\n",
    "    ):\n",
    "        # get model config\n",
    "        exp = get_exp(None, exp_name)\n",
    "        if conf is not None:\n",
    "            exp.test_conf = conf\n",
    "        if nms is not None:\n",
    "            exp.nmsthre = nms\n",
    "        if img_size is not None:\n",
    "            exp.test_size = (img_size, img_size)\n",
    "\n",
    "        # build yolox model\n",
    "        model = exp.get_model()\n",
    "        logger.info(\"Model Summary: {}\".format(get_model_info(model, exp.test_size)))\n",
    "        if device == \"gpu\":\n",
    "            model.cuda()\n",
    "            if fp16:\n",
    "                model.half()  # to FP16\n",
    "        model.eval()\n",
    "\n",
    "        # load model weights/checkpoint\n",
    "        logger.info(\"loading checkpoint\")\n",
    "        ckpt = torch.load(ckpt, map_location=\"cpu\")\n",
    "        model.load_state_dict(ckpt[\"model\"])\n",
    "        logger.info(\"loaded checkpoint done.\")\n",
    "\n",
    "        self.model = model\n",
    "        self.cls_names = cls_names\n",
    "        self.decoder = decoder\n",
    "        self.num_classes = exp.num_classes\n",
    "        self.confthre = exp.test_conf\n",
    "        self.nmsthre = exp.nmsthre\n",
    "        self.test_size = exp.test_size\n",
    "        self.device = device\n",
    "        self.fp16 = fp16\n",
    "        self.preproc = ValTransform(legacy=legacy)\n",
    "    \n",
    "    def predict(self, img):\n",
    "        img_info = {\"id\": 0}\n",
    "        if isinstance(img, str):\n",
    "            img_info[\"file_name\"] = os.path.basename(img)\n",
    "            img = cv2.imread(img)\n",
    "        else:\n",
    "            img_info[\"file_name\"] = None\n",
    "\n",
    "        height, width = img.shape[:2]\n",
    "        img_info[\"height\"] = height\n",
    "        img_info[\"width\"] = width\n",
    "        img_info[\"raw_img\"] = img\n",
    "\n",
    "        # to convert pixel coordinat from absolute value to relative\n",
    "        ratio = min(self.test_size[0] / img.shape[0], self.test_size[1] / img.shape[1])\n",
    "        img_info[\"ratio\"] = ratio\n",
    "\n",
    "        # preprocess img according to transform used when training\n",
    "        img, _ = self.preproc(img, None, self.test_size)\n",
    "        img = torch.from_numpy(img).unsqueeze(0)\n",
    "        img = img.float()\n",
    "        if self.device == \"gpu\":\n",
    "            img = img.cuda()\n",
    "            if self.fp16:\n",
    "                img = img.half()  # to FP16\n",
    "\n",
    "        # predict\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(img)\n",
    "            if self.decoder is not None:\n",
    "                outputs = self.decoder(outputs, dtype=outputs.type())\n",
    "            outputs = postprocess(\n",
    "                outputs, self.num_classes, self.confthre,\n",
    "                self.nmsthre, class_agnostic=True\n",
    "            )\n",
    "\n",
    "        # return result\n",
    "        results = []\n",
    "        if outputs[0] is None:\n",
    "            return results\n",
    "\n",
    "        else:\n",
    "            output = outputs[0].cpu()\n",
    "            bboxes = (output[:, 0:4]/ratio).type(torch.int).tolist()\n",
    "            cls = output[:, 6].type(torch.int).tolist()\n",
    "            scores = (output[:, 4] * output[:, 5]).tolist()\n",
    "            results = [bboxes, cls, scores, img_info]\n",
    "\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1v10lR_8_yvU"
   },
   "outputs": [],
   "source": [
    "def draw_bbox(img, bbox, classname):\n",
    "    w, h = 10 + (7*(len(classname))), 17\n",
    "    x0_name = bbox[0]\n",
    "    y0_name = bbox[1]\n",
    "    x1_name = x0_name + w\n",
    "    y1_name = y0_name + h\n",
    "\n",
    "    cv2.rectangle(img, (x0_name, y0_name), (x1_name, y1_name), (225, 225, 0), -1)\n",
    "    cv2.putText(\n",
    "                          img,\n",
    "                          classname,\n",
    "                          (x0_name+5,\n",
    "                          y0_name+12),\n",
    "                          cv2.FONT_HERSHEY_SIMPLEX,0.4,\n",
    "                          (255,255,255),\n",
    "                          1\n",
    "                      )\n",
    "    cv2.rectangle(img, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (225, 225, 0), 2)\n",
    "\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EJ1Py9Ea_8mJ"
   },
   "outputs": [],
   "source": [
    "# def process_video(cap, duration):\n",
    "#     ret_val, img = cap.read()\n",
    "#     row, col, ch = img.shape\n",
    "#     results = model.predict(img)\n",
    "#     if len(results) != 0:\n",
    "#         bboxes, cls_ids, scores, img_info = results\n",
    "\n",
    "#     cls_names = [COCO_CLASSES[idx] for idx in cls_ids]\n",
    "#     visualize_list = [\"car\", \"truck\", \"bus\", \"motorcycle\"]\n",
    "\n",
    "#     count = {cls_name:cls_names.count(cls_name) for cls_name in visualize_list}\n",
    "#     count[\"total\"] = sum(list(count.values()))\n",
    "#     # print(count[\"total\"])\n",
    "\n",
    "#     duration[0] = count[\"total\"]\n",
    "#     # duration[0] = 0\n",
    "#     # if count[\"total\"] <= 15:\n",
    "#     #     duration[0] = 15\n",
    "#     # elif count[\"total\"] <= 30:\n",
    "#     #     duration[0] = 30\n",
    "#     # else:\n",
    "#     #     duration[0] = 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O7Nllrpms953"
   },
   "outputs": [],
   "source": [
    "def process_video(video_path, model):\n",
    "  save_result = True\n",
    "  filename, ext = os.path.splitext(video_path)\n",
    "  save_path = filename + \"_result\" + ext\n",
    "\n",
    "  # instantiate videocapture\n",
    "  cap = cv2.VideoCapture(video_path)\n",
    "  width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)  # float\n",
    "  height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)  # float\n",
    "  fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "  # instantiate videowriter\n",
    "  if save_result:\n",
    "      logger.info(f\"video save_path is {save_path}\")\n",
    "      vid_writer = cv2.VideoWriter(\n",
    "          save_path, cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (int(width), int(height))\n",
    "      )\n",
    "  # loop through all frames\n",
    "  while True:\n",
    "    # read frame per frame\n",
    "    ret_val, img = cap.read()\n",
    "    # if frame is not none\n",
    "    if ret_val:\n",
    "        row, col, ch = img.shape\n",
    "        # predict object\n",
    "        results = model.predict(img)\n",
    "        if len(results) != 0:\n",
    "            bboxes, cls_ids, scores, img_info = results\n",
    "\n",
    "        # convert obj_class_ids to obj_class_names\n",
    "        cls_names = [COCO_CLASSES[idx] for idx in cls_ids]\n",
    "        \n",
    "        # filter out unused class from visualization\n",
    "        visualize_list = [\"car\", \"truck\", \"bus\", \"motorcycle\"]\n",
    "        for bbox, cls_name, score in zip(bboxes, cls_names, scores):\n",
    "            if cls_name in visualize_list:\n",
    "                img = draw_bbox(img, bbox, cls_name)\n",
    "\n",
    "        # counting\n",
    "        count = {cls_name:cls_names.count(cls_name) for cls_name in visualize_list}\n",
    "        count[\"total\"] = sum(list(count.values()))\n",
    "        # print(count)\n",
    "\n",
    "        # duration logic\n",
    "        duration = 0\n",
    "        if count[\"total\"] <= 15:\n",
    "            duration = 15\n",
    "        elif count[\"total\"] <= 30:\n",
    "            duration = 30\n",
    "        else:\n",
    "            duration = 45\n",
    "\n",
    "        # put text in frame\n",
    "        cv2.putText(\n",
    "            img,\n",
    "            f\"total kendaraan: {count['total']}\",\n",
    "            (10,row-10),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,0.5,\n",
    "            (0,255,255),\n",
    "            1\n",
    "        )\n",
    "        cv2.putText(\n",
    "            img,\n",
    "            f\"durasi: {duration} detik\",\n",
    "            (10,row-25),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,0.5,\n",
    "            (0,255,255),\n",
    "            1\n",
    "        )\n",
    "\n",
    "        # save video result to save_path\n",
    "        if save_result:\n",
    "            vid_writer.write(img)\n",
    "        # else visualize directly\n",
    "        else:\n",
    "            cv2.namedWindow(\"yolox\", cv2.WINDOW_NORMAL)\n",
    "            cv2.imshow(\"yolox\", img)\n",
    "        ch = cv2.waitKey(1)\n",
    "        if ch == 27 or ch == ord(\"q\") or ch == ord(\"Q\"):\n",
    "            break\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t08iUy5lcraP",
    "outputId": "e1c922c9-f28c-4a9e-a7ae-8e54e4ed42fa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-31 12:32:34.895 | INFO     | __main__:__init__:28 - Model Summary: Params: 25.33M, Gflops: 166.46\n",
      "2022-08-31 12:32:38.915 | INFO     | __main__:__init__:36 - loading checkpoint\n",
      "2022-08-31 12:32:39.118 | INFO     | __main__:__init__:39 - loaded checkpoint done.\n",
      "2022-08-31 12:32:39.217 | INFO     | __main__:process_video:13 - video save_path is sample_data/Capture_02_result.wmv\n",
      "2022-08-31 12:32:39.220 | INFO     | __main__:process_video:13 - video save_path is sample_data/Capture_04_result.wmv\n",
      "2022-08-31 12:32:39.222 | INFO     | __main__:process_video:13 - video save_path is sample_data/Capture_01_result.wmv\n",
      "2022-08-31 12:32:39.223 | INFO     | __main__:process_video:13 - video save_path is sample_data/Capture_03_result.wmv\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # instantiate obj det model\n",
    "    model = Yolox(\n",
    "        exp_name=\"yolox-m\",\n",
    "        ckpt=\"yolox_m.pth\",\n",
    "        conf=0.2,\n",
    "        nms=0.45,\n",
    "        img_size=960,\n",
    "        device=\"gpu\",\n",
    "    )\n",
    "\n",
    "    # prepare input and output path\n",
    "    video_path1 = \"sample_data/Capture_01.wmv\"\n",
    "    video_path2 = \"sample_data/Capture_02.wmv\"\n",
    "    video_path3 = \"sample_data/Capture_03.wmv\"\n",
    "    video_path4 = \"sample_data/Capture_04.wmv\"\n",
    "    # process_video(video_path, model)\n",
    "\n",
    "    thread0 = Thread(target=process_video, args=(video_path1, model))\n",
    "    thread1 = Thread(target=process_video, args=(video_path2, model))\n",
    "    thread2 = Thread(target=process_video, args=(video_path3, model))    \n",
    "    thread3 = Thread(target=process_video, args=(video_path4, model))\n",
    "    \n",
    "    thread0.start()\n",
    "    thread1.start()\n",
    "    thread2.start()\n",
    "    thread3.start()\n",
    "    \n",
    "    thread0.join()\n",
    "    thread1.join()\n",
    "    thread2.join()\n",
    "    thread3.join()\n",
    "\n",
    "    # save_result = True\n",
    "    # filename, ext = os.path.splitext(video_path)\n",
    "    # save_path = filename + \"_result\" + ext\n",
    "\n",
    "    # # instantiate videocapture\n",
    "    # cap = cv2.VideoCapture(video_path)\n",
    "    # width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)  # float\n",
    "    # height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)  # float\n",
    "    # fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    # # instantiate videowriter\n",
    "    # if save_result:\n",
    "    #     logger.info(f\"video save_path is {save_path}\")\n",
    "    #     vid_writer = cv2.VideoWriter(\n",
    "    #         save_path, cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (int(width), int(height))\n",
    "    #     )\n",
    "    # # loop through all frames\n",
    "    # while True:\n",
    "    #     # read frame per frame\n",
    "    #     ret_val, img = cap.read()\n",
    "    #     # if frame is not none\n",
    "    #     if ret_val:\n",
    "    #         row, col, ch = img.shape\n",
    "    #         # predict object\n",
    "    #         results = model.predict(img)\n",
    "    #         if len(results) != 0:\n",
    "    #             bboxes, cls_ids, scores, img_info = results\n",
    "\n",
    "    #         # convert obj_class_ids to obj_class_names\n",
    "    #         cls_names = [COCO_CLASSES[idx] for idx in cls_ids]\n",
    "            \n",
    "    #         # filter out unused class from visualization\n",
    "    #         visualize_list = [\"car\", \"truck\", \"bus\", \"motorcycle\"]\n",
    "    #         for bbox, cls_name, score in zip(bboxes, cls_names, scores):\n",
    "    #             if cls_name in visualize_list:\n",
    "    #                 img = draw_bbox(img, bbox, cls_name)\n",
    "\n",
    "    #         # counting\n",
    "    #         count = {cls_name:cls_names.count(cls_name) for cls_name in visualize_list}\n",
    "    #         count[\"total\"] = sum(list(count.values()))\n",
    "    #         # print(count)\n",
    "\n",
    "    #         # duration logic\n",
    "    #         duration = 0\n",
    "    #         if count[\"total\"] <= 15:\n",
    "    #             duration = 15\n",
    "    #         elif count[\"total\"] <= 30:\n",
    "    #             duration = 30\n",
    "    #         else:\n",
    "    #             duration = 45\n",
    "\n",
    "    #         # put text in frame\n",
    "    #         cv2.putText(\n",
    "    #             img,\n",
    "    #             f\"total kendaraan: {count['total']}\",\n",
    "    #             (10,row-10),\n",
    "    #             cv2.FONT_HERSHEY_SIMPLEX,0.5,\n",
    "    #             (0,255,255),\n",
    "    #             1\n",
    "    #         )\n",
    "    #         cv2.putText(\n",
    "    #             img,\n",
    "    #             f\"durasi: {duration} detik\",\n",
    "    #             (10,row-25),\n",
    "    #             cv2.FONT_HERSHEY_SIMPLEX,0.5,\n",
    "    #             (0,255,255),\n",
    "    #             1\n",
    "    #         )\n",
    "\n",
    "    #         # save video result to save_path\n",
    "    #         if save_result:\n",
    "    #             vid_writer.write(img)\n",
    "    #         # else visualize directly\n",
    "    #         else:\n",
    "    #             cv2.namedWindow(\"yolox\", cv2.WINDOW_NORMAL)\n",
    "    #             cv2.imshow(\"yolox\", img)\n",
    "    #         ch = cv2.waitKey(1)\n",
    "    #         if ch == 27 or ch == ord(\"q\") or ch == ord(\"Q\"):\n",
    "    #             break\n",
    "    #     else:\n",
    "    #         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gGzyMsRPsoRk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E1KzYZ6bAFqn",
    "outputId": "2f5bc176-aeec-472f-d4b6-def121c8c725"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-31 07:19:47.662 | INFO     | __main__:__init__:28 - Model Summary: Params: 25.33M, Gflops: 166.46\n",
      "2022-08-31 07:19:47.717 | INFO     | __main__:__init__:36 - loading checkpoint\n",
      "2022-08-31 07:19:47.927 | INFO     | __main__:__init__:39 - loaded checkpoint done.\n"
     ]
    }
   ],
   "source": [
    "# buffer0 = [0]\n",
    "# buffer1 = [0]\n",
    "# prev_buffer0 = 0\n",
    "# prev_buffer1 = 0\n",
    "\n",
    "# model = Yolox(\n",
    "#     exp_name=\"yolox-m\",\n",
    "#     ckpt=\"yolox_m.pth\",\n",
    "#     conf=0.2,\n",
    "#     nms=0.45,\n",
    "#     img_size=960,\n",
    "#     device=\"gpu\",\n",
    "# )\n",
    "\n",
    "# video_path = \"sample_data/Capture_01.wmv\"\n",
    "# cap0 = cv2.VideoCapture(video_path)\n",
    "# cap1 = cv2.VideoCapture(video_path)\n",
    "# cap2 = cv2.VideoCapture(video_path)\n",
    "# cap3 = cv2.VideoCapture(video_path)\n",
    "\n",
    "# cap = cv2.VideoCapture('sample_data/Capture_01.wmv')\n",
    "# while(cap.isOpened()):\n",
    "#   ret, frame = cap.read()\n",
    "#   # gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "#   process_video(cap0, buffer0)\n",
    "#   if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#     break\n",
    "\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# # for i in range(150):\n",
    "# #     thread0 = Thread(target=process_video, args=(cap0, buffer0))\n",
    "# #     thread1 = Thread(target=process_video, args=(cap1, buffer1))\n",
    "# #     thread2 = Thread(target=process_video, args=(cap1, buffer1))\n",
    "# #     thread3 = Thread(target=process_video, args=(cap1, buffer1))\n",
    "# #     thread0.start()\n",
    "# #     thread1.start()\n",
    "# #     thread2.start()\n",
    "# #     thread3.start()\n",
    "# #     thread0.join()\n",
    "# #     thread1.join()\n",
    "# #     thread2.join()\n",
    "# #     thread3.join()\n",
    "\n",
    "# #     print(buffer0, buffer1)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "main.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
